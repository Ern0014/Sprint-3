{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder,  LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Agency', 'Agency Type', 'Distribution Channel', 'Product Name',\n",
       "       'Claim', 'Duration', 'Destination', 'Net Sales', 'Commision (in value)',\n",
       "       'Gender', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/User/Downloads/Travel_Insurance.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Missing Value Treatement\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agency                  False\n",
       "Agency Type             False\n",
       "Distribution Channel    False\n",
       "Product Name            False\n",
       "Claim                   False\n",
       "Duration                False\n",
       "Destination             False\n",
       "Net Sales               False\n",
       "Commision (in value)    False\n",
       "Gender                   True\n",
       "Age                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agency                      0\n",
       "Agency Type                 0\n",
       "Distribution Channel        0\n",
       "Product Name                0\n",
       "Claim                       0\n",
       "Duration                    0\n",
       "Destination                 0\n",
       "Net Sales                   0\n",
       "Commision (in value)        0\n",
       "Gender                  45107\n",
       "Age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reason of not replacing the missing for Gender is because the percentage of missing value is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63326 entries, 0 to 63325\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Agency                63326 non-null  object \n",
      " 1   Agency Type           63326 non-null  object \n",
      " 2   Distribution Channel  63326 non-null  object \n",
      " 3   Product Name          63326 non-null  object \n",
      " 4   Claim                 63326 non-null  object \n",
      " 5   Duration              63326 non-null  int64  \n",
      " 6   Destination           63326 non-null  object \n",
      " 7   Net Sales             63326 non-null  float64\n",
      " 8   Commision (in value)  63326 non-null  float64\n",
      " 9   Age                   63326 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#we can delete column Gender since it contain missing value\n",
    "# and we do not require it in modelling and evaluation\n",
    "column_df = df.dropna(axis=1)\n",
    "column_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otherwise, we can delete entire row with missing value \n",
    "#In this way we can achive better accuracy \n",
    "#but we would lose large amount of data due to high percentage of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Outlier Analysis\n",
    "from collections import Counter\n",
    "\n",
    "def detect_outliers(df, features):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for c in features:\n",
    "        #1st quartile\n",
    "        Q1 =  np.percentile(df[c],25)\n",
    "        #3rd quartile\n",
    "        Q3 = np.percentile(df[c],75)\n",
    "        #IQR\n",
    "        IQR = Q3 - Q1\n",
    "        #outlier step\n",
    "        outlier_step = IQR * 1.5\n",
    "        #detect outlier and their indices\n",
    "        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n",
    "        # store indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "   \n",
    "    outlier_indices = Counter(outlier_indices)\n",
    "    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63326 entries, 0 to 63325\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Agency                63326 non-null  object \n",
      " 1   Agency Type           63326 non-null  object \n",
      " 2   Distribution Channel  63326 non-null  object \n",
      " 3   Product Name          63326 non-null  object \n",
      " 4   Claim                 63326 non-null  object \n",
      " 5   Duration              63326 non-null  int64  \n",
      " 6   Destination           63326 non-null  object \n",
      " 7   Net Sales             63326 non-null  float64\n",
      " 8   Commision (in value)  63326 non-null  float64\n",
      " 9   Gender                18219 non-null  object \n",
      " 10  Age                   63326 non-null  int64  \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 9,\n",
       " 20,\n",
       " 24,\n",
       " 25,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 394,\n",
       " 396,\n",
       " 414,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 607,\n",
       " 613,\n",
       " 780,\n",
       " 781,\n",
       " 806,\n",
       " 807,\n",
       " 809,\n",
       " 810,\n",
       " 941,\n",
       " 1228,\n",
       " 1259,\n",
       " 1399,\n",
       " 1409,\n",
       " 1413,\n",
       " 1583,\n",
       " 1596,\n",
       " 1600,\n",
       " 1603,\n",
       " 1773,\n",
       " 1780,\n",
       " 2216,\n",
       " 2217,\n",
       " 2222,\n",
       " 2338,\n",
       " 2361,\n",
       " 2362,\n",
       " 2363,\n",
       " 2543,\n",
       " 2722,\n",
       " 2723,\n",
       " 2724,\n",
       " 2725,\n",
       " 2736,\n",
       " 2737,\n",
       " 2907,\n",
       " 2916,\n",
       " 3062,\n",
       " 3304,\n",
       " 3308,\n",
       " 3310,\n",
       " 3428,\n",
       " 3429,\n",
       " 3430,\n",
       " 3449,\n",
       " 3610,\n",
       " 3611,\n",
       " 3612,\n",
       " 3613,\n",
       " 3769,\n",
       " 3770,\n",
       " 3771,\n",
       " 3772,\n",
       " 3930,\n",
       " 3949,\n",
       " 4051,\n",
       " 4052,\n",
       " 4068,\n",
       " 4069,\n",
       " 4070,\n",
       " 4071,\n",
       " 4160,\n",
       " 4289,\n",
       " 4420,\n",
       " 4421,\n",
       " 4429,\n",
       " 4552,\n",
       " 4553,\n",
       " 4719,\n",
       " 4722,\n",
       " 4724,\n",
       " 4726,\n",
       " 4732,\n",
       " 4734,\n",
       " 4763,\n",
       " 4764,\n",
       " 4945,\n",
       " 4946,\n",
       " 4947,\n",
       " 5163,\n",
       " 5164,\n",
       " 5165,\n",
       " 5166,\n",
       " 5192,\n",
       " 5436,\n",
       " 5437,\n",
       " 5438,\n",
       " 5439,\n",
       " 5599,\n",
       " 5600,\n",
       " 5601,\n",
       " 5801,\n",
       " 5802,\n",
       " 5816,\n",
       " 5996,\n",
       " 6012,\n",
       " 6211,\n",
       " 6212,\n",
       " 6213,\n",
       " 6404,\n",
       " 6574,\n",
       " 6575,\n",
       " 6576,\n",
       " 6711,\n",
       " 6715,\n",
       " 6878,\n",
       " 6879,\n",
       " 6983,\n",
       " 7101,\n",
       " 7102,\n",
       " 7116,\n",
       " 7266,\n",
       " 7267,\n",
       " 7268,\n",
       " 7269,\n",
       " 7276,\n",
       " 7492,\n",
       " 7493,\n",
       " 7494,\n",
       " 7495,\n",
       " 7496,\n",
       " 7508,\n",
       " 7666,\n",
       " 7679,\n",
       " 7680,\n",
       " 7698,\n",
       " 7816,\n",
       " 7826,\n",
       " 7922,\n",
       " 7924,\n",
       " 7940,\n",
       " 7941,\n",
       " 8115,\n",
       " 8116,\n",
       " 8135,\n",
       " 8292,\n",
       " 8293,\n",
       " 8330,\n",
       " 8527,\n",
       " 8528,\n",
       " 8529,\n",
       " 8530,\n",
       " 8532,\n",
       " 8735,\n",
       " 8736,\n",
       " 8751,\n",
       " 8932,\n",
       " 8933,\n",
       " 8938,\n",
       " 9267,\n",
       " 9268,\n",
       " 9269,\n",
       " 9270,\n",
       " 9479,\n",
       " 9480,\n",
       " 9688,\n",
       " 9690,\n",
       " 9691,\n",
       " 9692,\n",
       " 9910,\n",
       " 9949,\n",
       " 9950,\n",
       " 9969,\n",
       " 10188,\n",
       " 10191,\n",
       " 10392,\n",
       " 10596,\n",
       " 10611,\n",
       " 10750,\n",
       " 10751,\n",
       " 10950,\n",
       " 10951,\n",
       " 10969,\n",
       " 11208,\n",
       " 11214,\n",
       " 11424,\n",
       " 11438,\n",
       " 11439,\n",
       " 11440,\n",
       " 11913,\n",
       " 12093,\n",
       " 12454,\n",
       " 12455,\n",
       " 12461,\n",
       " 12705,\n",
       " 12706,\n",
       " 12707,\n",
       " 12708,\n",
       " 12733,\n",
       " 12973,\n",
       " 13195,\n",
       " 13230,\n",
       " 13431,\n",
       " 13432,\n",
       " 13433,\n",
       " 13596,\n",
       " 13732,\n",
       " 13734,\n",
       " 13736,\n",
       " 14281,\n",
       " 14313,\n",
       " 14358,\n",
       " 14365,\n",
       " 14366,\n",
       " 14367,\n",
       " 14368,\n",
       " 14369,\n",
       " 14582,\n",
       " 14613,\n",
       " 14623,\n",
       " 14797,\n",
       " 14798,\n",
       " 14947,\n",
       " 14948,\n",
       " 15115,\n",
       " 15747,\n",
       " 15748,\n",
       " 15749,\n",
       " 15779,\n",
       " 15946,\n",
       " 16152,\n",
       " 16361,\n",
       " 16363,\n",
       " 16365,\n",
       " 16366,\n",
       " 16382,\n",
       " 16384,\n",
       " 16400,\n",
       " 16455,\n",
       " 16588,\n",
       " 16776,\n",
       " 16777,\n",
       " 16797,\n",
       " 17044,\n",
       " 17045,\n",
       " 17046,\n",
       " 17047,\n",
       " 17048,\n",
       " 17049,\n",
       " 17050,\n",
       " 17051,\n",
       " 17076,\n",
       " 17304,\n",
       " 17305,\n",
       " 17306,\n",
       " 17307,\n",
       " 17308,\n",
       " 17309,\n",
       " 17559,\n",
       " 17560,\n",
       " 17561,\n",
       " 17562,\n",
       " 17563,\n",
       " 17564,\n",
       " 17565,\n",
       " 17772,\n",
       " 17773,\n",
       " 17964,\n",
       " 18125,\n",
       " 18126,\n",
       " 18127,\n",
       " 18128,\n",
       " 18318,\n",
       " 18319,\n",
       " 18320,\n",
       " 18321,\n",
       " 18322,\n",
       " 18331,\n",
       " 18518,\n",
       " 18562,\n",
       " 18563,\n",
       " 18564,\n",
       " 18565,\n",
       " 18569,\n",
       " 18797,\n",
       " 18798,\n",
       " 18799,\n",
       " 18800,\n",
       " 18801,\n",
       " 19013,\n",
       " 19014,\n",
       " 19015,\n",
       " 19016,\n",
       " 19017,\n",
       " 19018,\n",
       " 19197,\n",
       " 19198,\n",
       " 19351,\n",
       " 19352,\n",
       " 19487,\n",
       " 19658,\n",
       " 19659,\n",
       " 19660,\n",
       " 19661,\n",
       " 19662,\n",
       " 19885,\n",
       " 19886,\n",
       " 19887,\n",
       " 19888,\n",
       " 19889,\n",
       " 19890,\n",
       " 19891,\n",
       " 19892,\n",
       " 20104,\n",
       " 20105,\n",
       " 20106,\n",
       " 20107,\n",
       " 20108,\n",
       " 20109,\n",
       " 20110,\n",
       " 20111,\n",
       " 20117,\n",
       " 20348,\n",
       " 20550,\n",
       " 20551,\n",
       " 20552,\n",
       " 20553,\n",
       " 20761,\n",
       " 20938,\n",
       " 21174,\n",
       " 21175,\n",
       " 21176,\n",
       " 21177,\n",
       " 21178,\n",
       " 21179,\n",
       " 21180,\n",
       " 21181,\n",
       " 21182,\n",
       " 21183,\n",
       " 21184,\n",
       " 21446,\n",
       " 21447,\n",
       " 21448,\n",
       " 21449,\n",
       " 21451,\n",
       " 21452,\n",
       " 21453,\n",
       " 21454,\n",
       " 21697,\n",
       " 21703,\n",
       " 21722,\n",
       " 21723,\n",
       " 21724,\n",
       " 21725,\n",
       " 21726,\n",
       " 21727,\n",
       " 21906,\n",
       " 21955,\n",
       " 21956,\n",
       " 21957,\n",
       " 21959,\n",
       " 21960,\n",
       " 21961,\n",
       " 22123,\n",
       " 22144,\n",
       " 22158,\n",
       " 22159,\n",
       " 22160,\n",
       " 22161,\n",
       " 22162,\n",
       " 22296,\n",
       " 22338,\n",
       " 22470,\n",
       " 22482,\n",
       " 22483,\n",
       " 22484,\n",
       " 22485,\n",
       " 22604,\n",
       " 22623,\n",
       " 22629,\n",
       " 22630,\n",
       " 22631,\n",
       " 22632,\n",
       " 22633,\n",
       " 22634,\n",
       " 22641,\n",
       " 22644,\n",
       " 22693,\n",
       " 22694,\n",
       " 22695,\n",
       " 22696,\n",
       " 22697,\n",
       " 22706,\n",
       " 22713,\n",
       " 22880,\n",
       " 22881,\n",
       " 22882,\n",
       " 22883,\n",
       " 22884,\n",
       " 22891,\n",
       " 23102,\n",
       " 23103,\n",
       " 23104,\n",
       " 23105,\n",
       " 23106,\n",
       " 23107,\n",
       " 23108,\n",
       " 23109,\n",
       " 23110,\n",
       " 23134,\n",
       " 23333,\n",
       " 23334,\n",
       " 23335,\n",
       " 23336,\n",
       " 23337,\n",
       " 23338,\n",
       " 23339,\n",
       " 23340,\n",
       " 23542,\n",
       " 23545,\n",
       " 23568,\n",
       " 23569,\n",
       " 23570,\n",
       " 23571,\n",
       " 23572,\n",
       " 23573,\n",
       " 23580,\n",
       " 23788,\n",
       " 23789,\n",
       " 23790,\n",
       " 23791,\n",
       " 23953,\n",
       " 23954,\n",
       " 24026,\n",
       " 24151,\n",
       " 24165,\n",
       " 24166,\n",
       " 24167,\n",
       " 24168,\n",
       " 24169,\n",
       " 24198,\n",
       " 24339,\n",
       " 24382,\n",
       " 24383,\n",
       " 24384,\n",
       " 24385,\n",
       " 24386,\n",
       " 24387,\n",
       " 24388,\n",
       " 24389,\n",
       " 24390,\n",
       " 24391,\n",
       " 24555,\n",
       " 24556,\n",
       " 24759,\n",
       " 24760,\n",
       " 24761,\n",
       " 24767,\n",
       " 24776,\n",
       " 24953,\n",
       " 24973,\n",
       " 24974,\n",
       " 24975,\n",
       " 24976,\n",
       " 24977,\n",
       " 24978,\n",
       " 25041,\n",
       " 25149,\n",
       " 25150,\n",
       " 25151,\n",
       " 25282,\n",
       " 25291,\n",
       " 25292,\n",
       " 25456,\n",
       " 25457,\n",
       " 25458,\n",
       " 25459,\n",
       " 25460,\n",
       " 25461,\n",
       " 25657,\n",
       " 25658,\n",
       " 25659,\n",
       " 25660,\n",
       " 25661,\n",
       " 25662,\n",
       " 25674,\n",
       " 25871,\n",
       " 25872,\n",
       " 25873,\n",
       " 25874,\n",
       " 25875,\n",
       " 25888,\n",
       " 26051,\n",
       " 26052,\n",
       " 26053,\n",
       " 26214,\n",
       " 26215,\n",
       " 26359,\n",
       " 26367,\n",
       " 26368,\n",
       " 26369,\n",
       " 26370,\n",
       " 26523,\n",
       " 26524,\n",
       " 26525,\n",
       " 26526,\n",
       " 26527,\n",
       " 26706,\n",
       " 26707,\n",
       " 26708,\n",
       " 26709,\n",
       " 26710,\n",
       " 26711,\n",
       " 26910,\n",
       " 26911,\n",
       " 26912,\n",
       " 26913,\n",
       " 26914,\n",
       " 26915,\n",
       " 26916,\n",
       " 26917,\n",
       " 27100,\n",
       " 27101,\n",
       " 27102,\n",
       " 27103,\n",
       " 27105,\n",
       " 27124,\n",
       " 27278,\n",
       " 27279,\n",
       " 27280,\n",
       " 27455,\n",
       " 27464,\n",
       " 27465,\n",
       " 27592,\n",
       " 27780,\n",
       " 27889,\n",
       " 27890,\n",
       " 27891,\n",
       " 27892,\n",
       " 28109,\n",
       " 28328,\n",
       " 28329,\n",
       " 28337,\n",
       " 28479,\n",
       " 28482,\n",
       " 28505,\n",
       " 28517,\n",
       " 28523,\n",
       " 28591,\n",
       " 28592,\n",
       " 28593,\n",
       " 28594,\n",
       " 28595,\n",
       " 28596,\n",
       " 28758,\n",
       " 28772,\n",
       " 28773,\n",
       " 28774,\n",
       " 28941,\n",
       " 28942,\n",
       " 29088,\n",
       " 29253,\n",
       " 29254,\n",
       " 29255,\n",
       " 29256,\n",
       " 29446,\n",
       " 29447,\n",
       " 29448,\n",
       " 29449,\n",
       " 29636,\n",
       " 29637,\n",
       " 29638,\n",
       " 29639,\n",
       " 29640,\n",
       " 29641,\n",
       " 29642,\n",
       " 29669,\n",
       " 29849,\n",
       " 30015,\n",
       " 30016,\n",
       " 30017,\n",
       " 30033,\n",
       " 30158,\n",
       " 30159,\n",
       " 30160,\n",
       " 30161,\n",
       " 30162,\n",
       " 30163,\n",
       " 30300,\n",
       " 30301,\n",
       " 30302,\n",
       " 30327,\n",
       " 30489,\n",
       " 30490,\n",
       " 30491,\n",
       " 30492,\n",
       " 30493,\n",
       " 30494,\n",
       " 30659,\n",
       " 30704,\n",
       " 30705,\n",
       " 30706,\n",
       " 30707,\n",
       " 30708,\n",
       " 30716,\n",
       " 30722,\n",
       " 30723,\n",
       " 30879,\n",
       " 30880,\n",
       " 31040,\n",
       " 31041,\n",
       " 31042,\n",
       " 31052,\n",
       " 31183,\n",
       " 31219,\n",
       " 31220,\n",
       " 31221,\n",
       " 31222,\n",
       " 31223,\n",
       " 31375,\n",
       " 31382,\n",
       " 31514,\n",
       " 31515,\n",
       " 31669,\n",
       " 31670,\n",
       " 31693,\n",
       " 31826,\n",
       " 31827,\n",
       " 31828,\n",
       " 31829,\n",
       " 31830,\n",
       " 31831,\n",
       " 31832,\n",
       " 31834,\n",
       " 31839,\n",
       " 31853,\n",
       " 32043,\n",
       " 32408,\n",
       " 32419,\n",
       " 32423,\n",
       " 32507,\n",
       " 32514,\n",
       " 32515,\n",
       " 32516,\n",
       " 32601,\n",
       " 32717,\n",
       " 32718,\n",
       " 32869,\n",
       " 32870,\n",
       " 32876,\n",
       " 32877,\n",
       " 32878,\n",
       " 32879,\n",
       " 32880,\n",
       " 33053,\n",
       " 33054,\n",
       " 33055,\n",
       " 33056,\n",
       " 33239,\n",
       " 33240,\n",
       " 33446,\n",
       " 33447,\n",
       " 33448,\n",
       " 33567,\n",
       " 33568,\n",
       " 33571,\n",
       " 33577,\n",
       " 33641,\n",
       " 33642,\n",
       " 33749,\n",
       " 33916,\n",
       " 33928,\n",
       " 33990,\n",
       " 33995,\n",
       " 33996,\n",
       " 33997,\n",
       " 33998,\n",
       " 34170,\n",
       " 34195,\n",
       " 34201,\n",
       " 34206,\n",
       " 34207,\n",
       " 34208,\n",
       " 34209,\n",
       " 34210,\n",
       " 34211,\n",
       " 34212,\n",
       " 34338,\n",
       " 34533,\n",
       " 34535,\n",
       " 34547,\n",
       " 34551,\n",
       " 34723,\n",
       " 34763,\n",
       " 34764,\n",
       " 34765,\n",
       " 34766,\n",
       " 34780,\n",
       " 34806,\n",
       " 34896,\n",
       " 34932,\n",
       " 34933,\n",
       " 34934,\n",
       " 35043,\n",
       " 35081,\n",
       " 35082,\n",
       " 35083,\n",
       " 35190,\n",
       " 35238,\n",
       " 35245,\n",
       " 35248,\n",
       " 35251,\n",
       " 35402,\n",
       " 35404,\n",
       " 35468,\n",
       " 35469,\n",
       " 35470,\n",
       " 35471,\n",
       " 35472,\n",
       " 35478,\n",
       " 35604,\n",
       " 35616,\n",
       " 35617,\n",
       " 35704,\n",
       " 35706,\n",
       " 35707,\n",
       " 35708,\n",
       " 35735,\n",
       " 35821,\n",
       " 35822,\n",
       " 35823,\n",
       " 35892,\n",
       " 35893,\n",
       " 35894,\n",
       " 36022,\n",
       " 36023,\n",
       " 36024,\n",
       " 36025,\n",
       " 36026,\n",
       " 36028,\n",
       " 36029,\n",
       " 36060,\n",
       " 36082,\n",
       " 36135,\n",
       " 36136,\n",
       " 36137,\n",
       " 36138,\n",
       " 36139,\n",
       " 36227,\n",
       " 36241,\n",
       " 36385,\n",
       " 36407,\n",
       " 36428,\n",
       " 36429,\n",
       " 36430,\n",
       " 36431,\n",
       " 36440,\n",
       " 36618,\n",
       " 36720,\n",
       " 36721,\n",
       " 36745,\n",
       " 36782,\n",
       " 36783,\n",
       " 36784,\n",
       " 36785,\n",
       " 36786,\n",
       " 36793,\n",
       " 36802,\n",
       " 36904,\n",
       " 37080,\n",
       " 37143,\n",
       " 37144,\n",
       " 37266,\n",
       " 37336,\n",
       " 37337,\n",
       " 37338,\n",
       " 37339,\n",
       " 37464,\n",
       " 37470,\n",
       " 37471,\n",
       " 37472,\n",
       " 37473,\n",
       " 37474,\n",
       " 37475,\n",
       " 37476,\n",
       " 37477,\n",
       " 37585,\n",
       " 37611,\n",
       " 37615,\n",
       " 37706,\n",
       " 37767,\n",
       " 37915,\n",
       " 37940,\n",
       " 37941,\n",
       " 37949,\n",
       " 38091,\n",
       " 38125,\n",
       " 38126,\n",
       " 38271,\n",
       " 38326,\n",
       " 38327,\n",
       " 38328,\n",
       " 38329,\n",
       " 38441,\n",
       " 38463,\n",
       " 38471,\n",
       " 38499,\n",
       " 38500,\n",
       " 38501,\n",
       " 38600,\n",
       " 38658,\n",
       " 38668,\n",
       " 38669,\n",
       " 38670,\n",
       " 38671,\n",
       " 38672,\n",
       " 38788,\n",
       " 38810,\n",
       " 38811,\n",
       " 38812,\n",
       " 38826,\n",
       " 38956,\n",
       " 38972,\n",
       " 39004,\n",
       " 39005,\n",
       " 39006,\n",
       " 39007,\n",
       " 39008,\n",
       " 39164,\n",
       " 39190,\n",
       " 39191,\n",
       " 39192,\n",
       " 39193,\n",
       " 39195,\n",
       " 39196,\n",
       " 39197,\n",
       " 39199,\n",
       " 39201,\n",
       " 39202,\n",
       " 39205,\n",
       " 39229,\n",
       " 39259,\n",
       " 39276,\n",
       " 39294,\n",
       " 39458,\n",
       " 39469,\n",
       " 39500,\n",
       " 39501,\n",
       " 39502,\n",
       " 39503,\n",
       " 39516,\n",
       " 39631,\n",
       " 39677,\n",
       " 39714,\n",
       " 39715,\n",
       " 39716,\n",
       " 39717,\n",
       " 39728,\n",
       " 39893,\n",
       " 39900,\n",
       " 39901,\n",
       " 40032,\n",
       " 40076,\n",
       " 40077,\n",
       " 40078,\n",
       " 40190,\n",
       " 40239,\n",
       " 40410,\n",
       " 40549,\n",
       " 40558,\n",
       " 40560,\n",
       " 40582,\n",
       " 40609,\n",
       " 40646,\n",
       " 40766,\n",
       " 40767,\n",
       " 40770,\n",
       " 40867,\n",
       " 40912,\n",
       " 40913,\n",
       " 41068,\n",
       " 41069,\n",
       " 41080,\n",
       " 41260,\n",
       " 41261,\n",
       " 41262,\n",
       " 41263,\n",
       " 41406,\n",
       " 41452,\n",
       " 41453,\n",
       " 41454,\n",
       " 41455,\n",
       " 41456,\n",
       " 41457,\n",
       " 41458,\n",
       " 41459,\n",
       " 41587,\n",
       " 41646,\n",
       " 41647,\n",
       " 41648,\n",
       " 41840,\n",
       " 41857,\n",
       " 41858,\n",
       " 41859,\n",
       " 41860,\n",
       " 42058,\n",
       " 42089,\n",
       " 42175,\n",
       " 42211,\n",
       " 42212,\n",
       " 42213,\n",
       " 42214,\n",
       " 42215,\n",
       " 42216,\n",
       " 42217,\n",
       " 42218,\n",
       " 42219,\n",
       " 42232,\n",
       " 42342,\n",
       " 42346,\n",
       " 42400,\n",
       " 42401,\n",
       " 42549,\n",
       " 42648,\n",
       " 42659,\n",
       " 42660,\n",
       " 42661,\n",
       " 42781,\n",
       " 43068,\n",
       " 43069,\n",
       " 43070,\n",
       " 43071,\n",
       " 43072,\n",
       " 43073,\n",
       " 43221,\n",
       " 43222,\n",
       " 43223,\n",
       " 43334,\n",
       " 43378,\n",
       " 43379,\n",
       " 43380,\n",
       " 43381,\n",
       " 43382,\n",
       " 43383,\n",
       " 43384,\n",
       " 43385,\n",
       " 43507,\n",
       " 43508,\n",
       " 43509,\n",
       " 43510,\n",
       " 43511,\n",
       " 43512,\n",
       " 43513,\n",
       " 43514,\n",
       " 43551,\n",
       " 43640,\n",
       " 43685,\n",
       " 43686,\n",
       " 43687,\n",
       " 43688,\n",
       " 43689,\n",
       " 43690,\n",
       " 43691,\n",
       " 43692,\n",
       " 43693,\n",
       " 43694,\n",
       " 43695,\n",
       " 43700,\n",
       " 43876,\n",
       " 43877,\n",
       " 43878,\n",
       " 43879,\n",
       " 43880,\n",
       " 43881,\n",
       " 43882,\n",
       " 43883,\n",
       " 44030,\n",
       " 44062,\n",
       " 44063,\n",
       " 44064,\n",
       " 44065,\n",
       " 44066,\n",
       " 44246,\n",
       " 44247,\n",
       " 44248,\n",
       " 44249,\n",
       " 44250,\n",
       " 44251,\n",
       " 44252,\n",
       " 44253,\n",
       " 44254,\n",
       " 44255,\n",
       " 44256,\n",
       " 44257,\n",
       " ...]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_outliers(df,[\"Duration\",\"Net Sales\",\"Commision (in value)\",\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Genderismissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>80</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.95</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Value Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>66</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.75</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>MYANMAR</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.55</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>73</td>\n",
       "      <td>VIET NAM</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Bronze Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>66</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>57.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>67</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.40</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14843</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>2 way Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>65</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>78</td>\n",
       "      <td>INDONESIA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20372</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>74</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29948</th>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>73</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33948</th>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Bronze Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>68</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>47.0</td>\n",
       "      <td>11.75</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34182</th>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Bronze Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>67</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>53.5</td>\n",
       "      <td>13.38</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40745</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>80</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.25</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41216</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>67</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43029</th>\n",
       "      <td>TST</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Travel Cruise Protect</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43030</th>\n",
       "      <td>TST</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Travel Cruise Protect</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47123</th>\n",
       "      <td>TST</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Travel Cruise Protect</td>\n",
       "      <td>No</td>\n",
       "      <td>72</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47132</th>\n",
       "      <td>TST</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Travel Cruise Protect</td>\n",
       "      <td>No</td>\n",
       "      <td>71</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48997</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53951</th>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>65</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58576</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>77</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>19.8</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62786</th>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Online</td>\n",
       "      <td>Bronze Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>M</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Agency    Agency Type Distribution Channel  \\\n",
       "3171     JZI       Airlines               Online   \n",
       "4049     JZI       Airlines               Online   \n",
       "4284     JZI       Airlines               Online   \n",
       "4712     JZI       Airlines               Online   \n",
       "8689     JZI       Airlines               Online   \n",
       "11908    C2B       Airlines               Online   \n",
       "12236    JZI       Airlines               Online   \n",
       "12686    JZI       Airlines               Online   \n",
       "14812    CWT  Travel Agency               Online   \n",
       "14843    EPX  Travel Agency               Online   \n",
       "20305    JZI       Airlines               Online   \n",
       "20372    CWT  Travel Agency               Online   \n",
       "29948    EPX  Travel Agency               Online   \n",
       "33948    C2B       Airlines               Online   \n",
       "34182    C2B       Airlines               Online   \n",
       "40745    JZI       Airlines               Online   \n",
       "41216    JZI       Airlines               Online   \n",
       "43029    TST  Travel Agency              Offline   \n",
       "43030    TST  Travel Agency              Offline   \n",
       "47123    TST  Travel Agency              Offline   \n",
       "47132    TST  Travel Agency              Offline   \n",
       "48997    CWT  Travel Agency               Online   \n",
       "53951    JZI       Airlines               Online   \n",
       "58576    CWT  Travel Agency               Online   \n",
       "62786    C2B       Airlines               Online   \n",
       "\n",
       "                          Product Name Claim  Duration    Destination  \\\n",
       "3171                        Basic Plan    No        80    PHILIPPINES   \n",
       "4049                        Value Plan    No        66      HONG KONG   \n",
       "4284                        Basic Plan    No        72        MYANMAR   \n",
       "4712                        Basic Plan    No        72      INDONESIA   \n",
       "8689                        Basic Plan    No        73       VIET NAM   \n",
       "11908                      Bronze Plan    No        66      SINGAPORE   \n",
       "12236                       Basic Plan    No        67    PHILIPPINES   \n",
       "12686                       Basic Plan    No        79          CHINA   \n",
       "14812  Rental Vehicle Excess Insurance    No        79         FRANCE   \n",
       "14843         2 way Comprehensive Plan    No        65  UNITED STATES   \n",
       "20305                       Basic Plan    No        78      INDONESIA   \n",
       "20372  Rental Vehicle Excess Insurance    No        74          SPAIN   \n",
       "29948                Cancellation Plan    No        73  UNITED STATES   \n",
       "33948                      Bronze Plan    No        68      SINGAPORE   \n",
       "34182                      Bronze Plan    No        67      SINGAPORE   \n",
       "40745                       Basic Plan    No        80          JAPAN   \n",
       "41216                       Basic Plan    No        67       THAILAND   \n",
       "43029            Travel Cruise Protect    No        72       MALAYSIA   \n",
       "43030            Travel Cruise Protect    No        72       MALAYSIA   \n",
       "47123            Travel Cruise Protect    No        72       THAILAND   \n",
       "47132            Travel Cruise Protect    No        71       THAILAND   \n",
       "48997  Rental Vehicle Excess Insurance    No        79         GREECE   \n",
       "53951                       Basic Plan    No        65    PHILIPPINES   \n",
       "58576  Rental Vehicle Excess Insurance    No        77       MALAYSIA   \n",
       "62786                      Bronze Plan    No        79      SINGAPORE   \n",
       "\n",
       "       Net Sales  Commision (in value) Gender  Age  Genderismissing  \n",
       "3171        37.0                 12.95      F   34            False  \n",
       "4049        45.0                 15.75      M   34            False  \n",
       "4284        42.0                 14.70      F   35            False  \n",
       "4712        33.0                 11.55      F   35            False  \n",
       "8689        30.0                 10.50      M   34            False  \n",
       "11908       57.0                 14.25      M   37            False  \n",
       "12236       42.0                 14.70      F   35            False  \n",
       "12686       44.0                 15.40      M   34            False  \n",
       "14812       19.8                 11.88    NaN   37             True  \n",
       "14843       73.0                  0.00    NaN   37             True  \n",
       "20305       30.0                 10.50      F   37            False  \n",
       "20372       19.8                 11.88    NaN   35             True  \n",
       "29948       74.0                  0.00    NaN   37             True  \n",
       "33948       47.0                 11.75      F   35            False  \n",
       "34182       53.5                 13.38      F   34            False  \n",
       "40745        0.0                 12.25      M   34            False  \n",
       "41216       30.0                 10.50      M   37            False  \n",
       "43029       30.0                 10.50      M   37            False  \n",
       "43030       30.0                 10.50      F   34            False  \n",
       "47123       30.0                 10.50      M   34            False  \n",
       "47132       30.0                 10.50      F   34            False  \n",
       "48997       19.8                 11.88    NaN   34             True  \n",
       "53951       42.0                 14.70      F   34            False  \n",
       "58576       19.8                 11.88    NaN   37             True  \n",
       "62786       39.0                  9.75      M   34            False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[detect_outliers(df,[\"Duration\",\"Net Sales\",\"Commision (in value)\",\"Age\"])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the outliear\n",
    "df_1 = df.drop(detect_outliers(df,[\"Duration\",\"Net Sales\",\"Commision (in value)\",\"Age\"]), axis=0).reset_index(drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "      <td>63326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.317074</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>9.809992</td>\n",
       "      <td>39.969981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.791566</td>\n",
       "      <td>48.845637</td>\n",
       "      <td>19.804388</td>\n",
       "      <td>14.017010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-389.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4881.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>283.500000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Duration     Net Sales  Commision (in value)           Age\n",
       "count  63326.000000  63326.000000          63326.000000  63326.000000\n",
       "mean      49.317074     40.702018              9.809992     39.969981\n",
       "std      101.791566     48.845637             19.804388     14.017010\n",
       "min       -2.000000   -389.000000              0.000000      0.000000\n",
       "25%        9.000000     18.000000              0.000000     35.000000\n",
       "50%       22.000000     26.530000              0.000000     36.000000\n",
       "75%       53.000000     48.000000             11.550000     43.000000\n",
       "max     4881.000000    810.000000            283.500000    118.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Duration\",\"Net Sales\",\"Commision (in value)\",\"Age\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration : 5566\n",
      "Net Sales : 5543\n",
      "Commision (in value) : 7063\n",
      "Age : 7422\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Duration\",\"Net Sales\",\"Commision (in value)\",\"Age\"]\n",
    "\n",
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(x,\":\", ((df[x] < (Q1 - 1.5 * IQR)) | (df[x] > (Q3 + 1.5 * IQR))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mean = df[x].mean()\n",
    "    median = df[x].median()\n",
    "    for k in range(len(df[x])):\n",
    "        if ((df[x][k] < (Q1 - 1.5 * IQR)) | (df[x][k] > (Q3 + 1.5 * IQR))):\n",
    "            df.loc[k, x] = median \n",
    "            if (x == \"Duration\"):\n",
    "                df.loc[k, x] = mean\n",
    "            if pd.isnull(df[x][k]):\n",
    "                if (x == \"Duration\"):\n",
    "                    df.loc[k, x] = mean\n",
    "                else:\n",
    "                    df.loc[k, x] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mean = df[x].mean()\n",
    "    median = df[x].median()\n",
    "    for k in range(len(df[x])):\n",
    "        if ((df[x][k] < (Q1 - 1.5 * IQR)) | (df[x][k] > (Q3 + 1.5 * IQR))):\n",
    "            df.loc[k, x] = median \n",
    "            if (x == \"Net Sales\"):\n",
    "                df.loc[k, x] = mean\n",
    "            if pd.isnull(df[x][k]):\n",
    "                if (x == \"Net Sales\"):\n",
    "                    df.loc[k, x] = mean\n",
    "                else:\n",
    "                    df.loc[k, x] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mean = df[x].mean()\n",
    "    median = df[x].median()\n",
    "    for k in range(len(df[x])):\n",
    "        if ((df[x][k] < (Q1 - 1.5 * IQR)) | (df[x][k] > (Q3 + 1.5 * IQR))):\n",
    "            df.loc[k, x] = median \n",
    "            if (x == \"Commision (in value)\"):\n",
    "                df.loc[k, x] = mean\n",
    "            if pd.isnull(df[x][k]):\n",
    "                if (x == \"Commision (in value)\"):\n",
    "                    df.loc[k, x] = mean\n",
    "                else:\n",
    "                    df.loc[k, x] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mean = df[x].mean()\n",
    "    median = df[x].median()\n",
    "    for k in range(len(df[x])):\n",
    "        if ((df[x][k] < (Q1 - 1.5 * IQR)) | (df[x][k] > (Q3 + 1.5 * IQR))):\n",
    "            df.loc[k, x] = median \n",
    "            if (x == \"Age\"):\n",
    "                df.loc[k, x] = mean\n",
    "            if pd.isnull(df[x][k]):\n",
    "                if (x == \"Age\"):\n",
    "                    df.loc[k, x] = mean\n",
    "                else:\n",
    "                    df.loc[k, x] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, \"Duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.70201797050243"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, \"Net Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, \"Commision (in value)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, \"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.57"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, \"Commision (in value)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration : 0\n",
      "Net Sales : 0\n",
      "Commision (in value) : 0\n",
      "Age : 0\n"
     ]
    }
   ],
   "source": [
    "for x in columns:\n",
    "    Q1 = df[x].quantile(0.25)\n",
    "    Q3 = df[x].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(x,\":\", ((df[x] < (Q1 - 1.5 * IQR)) | (df[x] > (Q3 + 1.5 * IQR))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Comprehensive Plan</td>\n",
       "      <td>No</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>23.712867</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>40.702018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>Online</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>No</td>\n",
       "      <td>23.712867</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency    Agency Type Distribution Channel                     Product Name  \\\n",
       "0    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "1    CBH  Travel Agency              Offline               Comprehensive Plan   \n",
       "2    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "3    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "4    CWT  Travel Agency               Online  Rental Vehicle Excess Insurance   \n",
       "\n",
       "  Claim   Duration Destination  Net Sales  Commision (in value) Gender  Age  \n",
       "0    No  22.000000    MALAYSIA  40.702018                   0.0      F   36  \n",
       "1    No  22.000000    MALAYSIA  40.702018                   0.0      F   36  \n",
       "2    No  23.712867   AUSTRALIA  40.702018                   0.0    NaN   36  \n",
       "3    No  22.000000   AUSTRALIA  40.702018                   0.0    NaN   36  \n",
       "4    No  23.712867       ITALY  27.000000                   0.0    NaN   36  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Data Transformation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63326 entries, 0 to 63325\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Agency                63326 non-null  object \n",
      " 1   Agency Type           63326 non-null  object \n",
      " 2   Distribution Channel  63326 non-null  object \n",
      " 3   Product Name          63326 non-null  object \n",
      " 4   Claim                 63326 non-null  object \n",
      " 5   Duration              63326 non-null  float64\n",
      " 6   Destination           63326 non-null  object \n",
      " 7   Net Sales             63326 non-null  float64\n",
      " 8   Commision (in value)  63326 non-null  float64\n",
      " 9   Gender                18219 non-null  object \n",
      " 10  Age                   63326 non-null  int64  \n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Claim'],axis=1)\n",
    "y = df['Claim']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train = enc.fit_transform(X_train)\n",
    "X_test = enc.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# fit on the training set\n",
    "lr.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = lr.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd =  SGDClassifier()\n",
    "# fit on the training set\n",
    "sgd.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = sgd.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "# fit on the training set\n",
    "decision_tree.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = decision_tree.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.30, score of: 98.30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "# fit on the training set\n",
    "random_forest.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = random_forest.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# cv = cross_val_score(random_forest, X_train, y_train,cv=5)\n",
    "# print('cross validation score of: %.2f' % (cv.mean()*100))\n",
    "score = random_forest.score(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + ', score of: %.2f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.46, score of: 98.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability = True, C = 1, kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "yhat = svc.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# cv = cross_val_score(random_forest, X_train, y_train,cv=5)\n",
    "# print('cross validation score of: %.2f' % (cv.mean()*100))\n",
    "score = svc.score(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + ', score of: %.2f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "49 fits failed out of a total of 70.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.98566984        nan        nan 0.98566984        nan 0.98566984\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 1e-06, 'solver': 'saga', 'penalty': 'l1', 'multi_class': 'ovr', 'max_iter': 100, 'C': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'saga', 'sag']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "c_values = [100, 80, 50, 30, 10, 5.0, 3.0, 1.0, 0.1, 0.2, 0.3, 0.6, 0.01, 0.02, 0.03, 0.001]\n",
    "tolerant = [0.1, 0.001, 0.001, 0.0015, 0.0001, 0.00013, 0.00001, 0.000001]\n",
    "max_iter = [100, 500, 1000, 5000, 10000, 50000]\n",
    "multi_class = ['auto', 'ovr', 'multinomial']\n",
    "\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values, tol=tolerant, max_iter=max_iter, multi_class=multi_class)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
    "model = LogisticRegression()\n",
    "\n",
    "lr_random = RandomizedSearchCV(estimator = model, param_distributions = grid, \n",
    "                                cv = 7, verbose=0, scoring=\"accuracy\")\n",
    "lr_random.fit(X_train, y_train)\n",
    "print(lr_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.47\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(tol=0.0001, solver='newton-cg', penalty='l2', multi_class='auto',max_iter=5000, C=0.1)\n",
    "# fit on the training set\n",
    "lr.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = lr.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.46, score of: 98.46\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C = 100, kernel='poly', gamma=0.01, degree=1)\n",
    "svc.fit(X_train, y_train)\n",
    "yhat = svc.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# cv = cross_val_score(random_forest, X_train, y_train,cv=5)\n",
    "# print('cross validation score of: %.2f' % (cv.mean()*100))\n",
    "score = svc.score(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + ', score of: %.2f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27, score of: 98.27\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C = 10, kernel='poly', gamma=0.1, degree=5)\n",
    "svc.fit(X_train, y_train)\n",
    "yhat = svc.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# cv = cross_val_score(random_forest, X_train, y_train,cv=5)\n",
    "# print('cross validation score of: %.2f' % (cv.mean()*100))\n",
    "score = svc.score(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + ', score of: %.2f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "63321     True\n",
       "63322     True\n",
       "63323     True\n",
       "63324     True\n",
       "63325     True\n",
       "Length: 63326, dtype: bool"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. New Feature (if any)\n",
    "#We can check whether a rows is duplicated \n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Feature Selection\n",
    "#predict Agency Type (Airlines or Travel Agency) based on 2 features\n",
    "df['Agency Type']= df['Agency Type'].replace({'Travel Agency': 0, 'Airlines': 1})\n",
    "feature_df=df.drop(['Agency', 'Distribution Channel', 'Product Name', 'Claim', 'Duration', 'Destination', 'Net Sales', 'Gender'], axis=1)\n",
    "feature_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array = feature_df.values\n",
    "X = array[:,1:3]\n",
    "Y = array[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=1)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "\n",
    "features = fit.transform(X)\n",
    "# Summarize selected features\n",
    "print(features[0:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the score for attribute 'Age' is higher, hence suggest it is the better feature than 'Commision (in value)' and\n",
    "# a stronger relationship with the output ('Agency Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Product Name'] = df['Product Name'].replace(['Travel Cruise Protect Family'],'Travel Cruise Protect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\t# retrieve numpy array\n",
    "\tdataset = df.values\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tX = dataset[:, :-1]\n",
    "\ty = dataset[:,-1]\n",
    "\t# format all fields as string\n",
    "\tX = X.astype(str)\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (63226, 10) (63226,)\n",
      "Test (100, 10) (100,)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X, y = load_dataset()\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=10)\n",
    "# summarize\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "\toe = OrdinalEncoder()\n",
    "\toe.fit(X_train)\n",
    "\tX_train_enc = oe.transform(X_train)\n",
    "\tX_test_enc = oe.transform(X_test)\n",
    "\treturn X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\treturn y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-Squared Feature Selection\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=chi2, k='all')\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 5686.874186\n",
      "Feature 1: 4518.167694\n",
      "Feature 2: 98.647076\n",
      "Feature 3: 75033.864612\n",
      "Feature 4: 359.999593\n",
      "Feature 5: 11148.773538\n",
      "Feature 6: 39449.628592\n",
      "Feature 7: 61890.803757\n",
      "Feature 8: 9949240.972831\n",
      "Feature 9: 4808.389667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input feature 3, 6, 7 and 8 are the most relevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutual Information Feature Selection\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\tfs = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "\tfs.fit(X_train, y_train)\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.464808\n",
      "Feature 1: 0.163213\n",
      "Feature 2: 0.021436\n",
      "Feature 3: 0.429419\n",
      "Feature 4: 0.000000\n",
      "Feature 5: 0.029488\n",
      "Feature 6: 0.172108\n",
      "Feature 7: 0.288582\n",
      "Feature 8: 0.442479\n",
      "Feature 9: 0.166048\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train_enc, y_train_enc, X_test_enc)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input feature 0, 3, 7, 8 are most relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the data contain categorical data. Types of feature selection here is filters method under supervised feature selection, in which we use chi-square test and mutual information. \n",
    "\n",
    "The Filter methodology uses the selected metric to identify irrelevant attributes and also filter out redundant columns from the models. It gives the option of isolating selected measures that enrich a model. The columns are ranked following the calculation of the feature scores.\n",
    "\n",
    "Advantages of Filter methods\n",
    "Filter methods are model agnostic(compatible)\n",
    "Rely entirely on features in the data set\n",
    "Computationally very fast\n",
    "Based on different statistical methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
